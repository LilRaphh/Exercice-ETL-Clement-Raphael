# Projet Int√©gr√© : √âvaluation de la Cor√©lation entre la m√©t√©o et le passage dans les rues de Rennes

## Technologies Utilis√©es

### Langage

![Python](https://img.shields.io/badge/Python-3.12.7-blue?logo=python&logoColor=white)

### Framework et outils de d√©veloppement

![Docker](https://img.shields.io/badge/Docker-20.10.7-blue?logo=docker&logoColor=white)


### Biblioth√®ques de Donn√©es & Machine Learning

![Pandas](https://img.shields.io/badge/Pandas-1.5.2-brightgreen?logo=pandas&logoColor=white)

### Outils de Visualisation

![Superset](https://img.shields.io/badge/SuperSet-version-blue?logo=Superset$logoColor=white)

## Introduction au Projet
---

Ces outils ont √©t√© utilis√© pour le developpement du Projet Exercice-ETL-Clement-Raphael. Ce dernier vise √† r√©cup√©rer des donn√©es provenant de diverses sources, comme une API et un site internet, afin de de les transformer, pour ensuite les analyser. Tout cela de mani√®re √† pouvoir en tirer des insights et potentiellement, par la suite, en faire des pr√©dictions.

## Objectif du Projet 
---
Ce projet vise √† combiner les donn√©es d'un site m√©t√©o (infoclimat) ainsi que les donn√©es fournies par une API Rennes Metropoles. Cete d√©marche permet de pouvoir d√©t√©cter des biais de comportements, que ce soit vis-√†-vis de la m√©t√©o mais aussi de p√©riodes de l'ann√©es, ou des √©v√©nements. Et cela afin de pouvoir au long terme donner des voies d'am√©lioration quant √† la circulation au sein de la m√©tropole de Rennes.

## Architecture du Projet
---

<img width="725" alt="Capture d‚Äô√©cran 2024-11-15 √† 15 15 31" src="https://github.com/user-attachments/assets/a07471d4-3756-4139-9e65-8cde17b39086">

## Workflow et sch√©ma d'architecture

1. **R√©cup√©ration des donn√©es (API et scrapping)** :

  - Exctration des donn√©es √† partir de la page m√©t√©o, √† l'aide d'un script Python.
  - R√©cup√©ration des donn√©es de l'API pour les transformer sous le m√™me format que le scrapping.

2. **Traitement des donn√©es**

  - **Transformation des donn√©es / Simplification :** Une fois la r√©cup√©ration de toutes les donn√©es, √† travers le scrapping de toutes les pages depuis le 1er janvier 2023, nettouage de toutes les donn√©es √† l'aide d'un second script python.
  - **merging des donn√©es :** merging des deux sources des donn√©es par la date.

3. **Envoie des donn√©es vers la base de donn√©e**

  - Envoie des donn√©es vers la base de donn√©es Postgres SQL √† partir de scripts Python.

4. **Visualisation et Analyse**

  - Superset r√©cup√©re les donn√©es pour cr√©er une visualisation

# **Guide d'Installation**

## **Pr√©requis**
Avant de commencer, assurez-vous d'avoir les outils suivants install√©s sur votre machine :
1. **Python 3.12.7** ou une version compatible.
   - V√©rifiez en ex√©cutant : `python --version` ou `python3 --version`.
2. **Docker** (version 20.10.7 ou ult√©rieure).
   - V√©rifiez en ex√©cutant : `docker --version`.
3. **Git** pour cloner le d√©p√¥t.
   - V√©rifiez en ex√©cutant : `git --version`.

---

## **√âtape 1 : Cloner le d√©p√¥t**
T√©l√©chargez le code source de ce projet depuis le d√©p√¥t GitHub :
```bash

git clone https://github.com/votre-utilisateur/Exercice-ETL-Clement-Raphael.git

cd Exercice-ETL-Clement-Raphael
```
---

## **√âtape 2 : Configurer l'environnement Python**

1. **Cr√©er un environnement virtuel** (recommand√© pour isoler les d√©pendances du projet) :
   - Sur Unix/macOS :
     ```bash
     python3 -m venv venv
     source venv/bin/activate
     ```
   - Sur Windows :
     ```bash
     python -m venv venv
     venv\Scripts\activate
     ```

2. **Mettre √† jour `pip` et installer les d√©pendances** :
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
---

## **√âtape 3 : Configurer Docker pour les services**
Certains services, comme les bases de donn√©es ou les outils de visualisation, peuvent √™tre ex√©cut√©s √† l'aide de Docker.

1. **Configurer le fichier `docker-compose.yml`** (si applicable) :
   - Modifiez les param√®tres si n√©cessaire, par exemple, les ports ou les chemins des volumes.
   - Exemple :
     ```yaml
     version: '3.8'
     services:
       database:
         image: postgres:latest
         container_name: my_postgres_db
         ports:
           - "5432:5432"
         environment:
           POSTGRES_USER: admin
           POSTGRES_PASSWORD: password
           POSTGRES_DB: my_database
         volumes:
           - db_data:/var/lib/postgresql/data
       superset:
         image: apache/superset:latest
         container_name: superset_app
         ports:
           - "8088:8088"
         environment:
           SUPERSET_CONFIG_PATH: /app/pythonpath/superset_config.py
         volumes:
           - ./superset_config:/app/pythonpath
     volumes:
       db_data:
     ```

2. **Lancer Docker** :
   ```bash
   docker-compose up -d
   ```

## **√âtape 4 : Configurer les Variables d‚ÄôEnvironnement**

Certaines fonctionnalit√©s n√©cessitent des cl√©s ou des configurations sp√©cifiques. Celles-ci peuvent √™tre centralis√©es dans un fichier .env.

**Cr√©er un fichier .env:**
   ```bash
   touch .env
   ```

=======
# üìú Conclusion

---

L‚Äôapplication d√©velopp√©e dans le cadre de ce projet met en lumi√®re l‚Äôinteraction entre les conditions m√©t√©orologiques et les flux de passage en diff√©rents points de la ville de Rennes. Gr√¢ce √† l‚Äôexploitation combin√©e de donn√©es issues d‚Äôun site m√©t√©o scrapp√© et d‚Äôune API d√©di√©e aux flux de passage, nous avons pu √©tablir des liens de corr√©lation int√©ressants tout au long de l‚Äôann√©e.

En s‚Äôappuyant sur des techniques de web scraping et d‚Äôint√©gration d‚ÄôAPI, l‚Äôapplication offre une analyse approfondie et quantifi√©e de la mani√®re dont les variations climatiques influencent les d√©placements urbains. Ces r√©sultats peuvent fournir des insights pr√©cieux pour les gestionnaires urbains, les commer√ßants, ou toute entit√© cherchant √† anticiper les comportements li√©s aux flux de population en fonction des conditions climatiques.

Les visualisations g√©n√©r√©es permettent d‚Äôexplorer ces corr√©lations de mani√®re intuitive et interactive, ouvrant la voie √† une meilleure compr√©hension des dynamiques urbaines. Ce projet pourrait √©galement servir de base pour des d√©veloppements futurs, tels que l‚Äôint√©gration de mod√®les pr√©dictifs ou l‚Äôanalyse de flux dans d‚Äôautres contextes g√©ographiques.

En conclusion, cette solution d√©montre comment des donn√©es disparates peuvent √™tre combin√©es et analys√©es pour r√©v√©ler des tendances utiles et exploitables. Elle repr√©sente une avanc√©e vers une gestion des flux urbains plus proactive, tout en soulignant le r√¥le cl√© des conditions environnementales dans la planification et la prise de d√©cision.

üöß Difficult√©s Rencontr√©es

  texte


## Am√©lioration future
---
  


## Contributeurs

  - Cl√©ment Metois (@Skyane) : Apprenti Data Scientist -**skayne.pro@gmail.com**-
  - Colnot Rapha√´l (@LilRaphh) : Apprenti Data Scientist -**colnotraphael@gmail.com**-


## Licence

Ce projet a √©t√© r√©aslis√© pour rendu en √©cole.









